# AI_Analyst

End-to-End Retrieval-Augmented AI Analyst for Complex Documents

**ğŸ“Œ Problem Statement**

This project implements an internal AI Analyst MVP for a consulting firm.
The system enables analysts to upload large documents (policies, manuals, financial reports) and ask complex, evidence-backed questions.

The system is designed to:

Understand different document types

Retrieve most relevant supporting evidence

Perform reasoning and synthesis

Produce structured, explainable outputs

Use a multi-agent workflow to orchestrate tools

Provide a usable UI for real analysts


**ğŸ§© Architecture Overview**

Pipeline Flow:

        User Uploads PDF
                â†“
        Semantic Ingestion & Chunking
                â†“
        Embedding + Metadata Storage (ChromaDB)
                â†“
        Query â†’ Query Analyzer Agent
                â†“
        Retrieval Agent (Hybrid Search)
                â†“
        Answer Agent (Reasoning + Citations)
                â†“
        Structured JSON Response
                â†“
        Frontend UI Rendering
        

# RAG System Implementation

**A. Ingestion**

PDF text extraction

Semantic chunking (not fixed-size)

Metadata preserved (source, page, section)

Embeddings stored in ChromaDB

**B. Retrieval (Hybrid)**

Three-stage retrieval:

Vector similarity (semantic)

BM25 keyword matching

Cross-ranking merge

**System Outputs:**

Top 5 ranked chunks

Retrieval diagnostics

Scores per strategy      


# Multi-Agent Workflow

Coordinates all agents and ensures task completion.

**Agent 1: Query Analyzer Agent**

Determines user intent (factual, reasoning, comparison, multi-hop)

Decides retrieval strategy

Rewrites queries if needed

Produces execution plan


**Agent 2: Retrieval Agent**

Executes hybrid retrieval

Ranks and filters chunks

Surfaces contradictory evidence

**Agent 3: Answer Agent**

Applies Answer Generation Prompt

Produces structured output

Responds as a domain analyst, not a chatbot


# ğŸ§± Tech Stack
**Backend** 

FastAPI (Python)

Azure OpenAI API (LLM)

ChromaDB (vector store)

Sentence Transformers (MiniLM-L6-v2)

BM25 (rank-bm25)

Python-dotenv

Uvicorn

**Frontend** 

React



# ğŸ“‚ Project Structure    


      ai_analyst_mvp/
      â”‚
      â”œâ”€â”€ backend/
      â”‚   â”œâ”€â”€ main.py
      â”‚   â”œâ”€â”€ agents.py
      â”‚   â”œâ”€â”€ retriever.py
      â”‚   â”œâ”€â”€ ingestion.py
      â”‚   â”œâ”€â”€ llm_tools.py
      â”‚   â”œâ”€â”€ prompts/
      â”‚   â”‚   â”œâ”€â”€ classifier_prompt.txt
      â”‚   â”‚   â”œâ”€â”€ answer_prompt.txt
      â”‚   â”‚   â”œâ”€â”€ summarization_prompt.txt
      â”‚   â”‚   â””â”€â”€ hidden_instruction.txt
      â”‚   â”œâ”€â”€ .env  (NOT COMMITTED)
      â”‚   â”œâ”€â”€ requirements.txt
      â”‚   â””â”€â”€ ...
      â”‚
      â”œâ”€â”€ frontend/
      â”‚   â”œâ”€â”€ public/index.html
      â”‚   â”œâ”€â”€ src/
      â”‚   â”‚   â”œâ”€â”€ App.jsx
      â”‚   â”‚   â”œâ”€â”€ styles.css
      â”‚   â”‚   â”œâ”€â”€ components/
      â”‚   â”‚   â”‚   â”œâ”€â”€ Upload.jsx
      â”‚   â”‚   â”‚   â”œâ”€â”€ Query.jsx
      â”‚   â”‚   â”‚   â””â”€â”€ Results.jsx
      â”‚   â”œâ”€â”€ package.json
      â”‚
      â”œâ”€â”€ .gitignore
      â””â”€â”€ README.md
      


# ğŸ” Environment Variables

Create a .env file inside /backend:

          AZURE_OPENAI_ENDPOINT=https://<your-resource>.cognitiveservices.azure.com/
          AZURE_OPENAI_API_KEY=<your-key>
          AZURE_OPENAI_API_VERSION=2024-08-01-preview
          AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini



# âš™ï¸ Backend Setup
1ï¸âƒ£ Activate virtual environment

      cd backend
      python3 -m venv .venv
      source .venv/bin/activate

2ï¸âƒ£ Install dependencies

    pip install -r requirements.txt

3ï¸âƒ£ Run the backend server

    uvicorn main:app --reload --port 8000

Backend runs at:

      http://127.0.0.1:8000


# ğŸŒ Frontend Setup
1ï¸âƒ£ Install packages

    cd frontend
    npm install

2ï¸âƒ£ Run React app

    npm start

Frontend runs at:

    http://localhost:3000
